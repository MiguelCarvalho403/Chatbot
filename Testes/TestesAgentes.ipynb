{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0320ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f757a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73676ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9468e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/migueldcarvalho/miniforge3/envs/DataScience/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e004c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\", device='cpu')\n",
    "client = QdrantClient(path=\"../metadados/VectorStore/\") # Carrega vectorstore em disco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96e3c2c",
   "metadata": {},
   "source": [
    "## tool class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1bbe0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool:\n",
    "    \"\"\"\n",
    "    A class representing a reusable piece of code (Tool).\n",
    "\n",
    "    Attributes:\n",
    "        name (str): Name of the tool.\n",
    "        description (str): A textual description of what the tool does.\n",
    "        func (callable): The function this tool wraps.\n",
    "        arguments (list): A list of arguments.\n",
    "        outputs (str or list): The return type(s) of the wrapped function.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 description: str,\n",
    "                 func: Callable,\n",
    "                 arguments: list,\n",
    "                 outputs: str):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.func = func\n",
    "        self.arguments = arguments\n",
    "        self.outputs = outputs\n",
    "\n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"\n",
    "        Return a string representation of the tool,\n",
    "        including its name, description, arguments, and outputs.\n",
    "        \"\"\"\n",
    "        args_str = \", \".join([\n",
    "            f\"{arg_name}: {arg_type}\" for arg_name, arg_type in self.arguments\n",
    "        ])\n",
    "\n",
    "        return (\n",
    "            f\"Tool Name: {self.name},\"\n",
    "            f\" Description: {self.description},\"\n",
    "            f\" Arguments: {args_str},\"\n",
    "            f\" Outputs: {self.outputs}\"\n",
    "        )\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Invoke the underlying function (callable) with provided arguments.\n",
    "        \"\"\"\n",
    "        return self.func(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355a568",
   "metadata": {},
   "source": [
    "## Chatbot class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c063f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class Chatbot:\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.tokenizer = kwargs.get('tokenizer')\n",
    "        self.model = kwargs.get('model')\n",
    "        self.history = []\n",
    "\n",
    "    def agent(self, prompt: dict) -> str:\n",
    "\n",
    "        # Suas ferramentas bem descritas\n",
    "        tools_description = [\n",
    "            {\n",
    "                \"name\": \"open_data_search\",\n",
    "                \"description\": \"Busca por dados públicos aberto governamentais. \"\n",
    "                \"Exemplos:\"\n",
    "                \"Quero dados sobre...\"\n",
    "                \"\"\n",
    "                \"Input: query de busca (string).\",\n",
    "                \"parameters\": { \"type\": \"object\", \"properties\": { \"query\": {\"type\": \"string\"} } }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"soma\",\n",
    "                \"description\": \"Deve ser acionado quando necessário somar dois numeros, Calculadora de adição (A + B). Input: a (float), b (float).\",\n",
    "                \"parameters\": { \"type\": \"object\", \"properties\": { \"a\": {\"type\": \"number\"}, \"b\": {\"type\": \"number\"} } }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        tools_str = json.dumps(tools_description, indent=2, ensure_ascii=False)\n",
    "\n",
    "        system_instruction = f\"\"\"\n",
    "        Você é um assistente AI útil e preciso.\n",
    "\n",
    "        ### FERRAMENTAS DISPONÍVEIS\n",
    "        Você tem acesso às seguintes ferramentas para responder ao usuário:\n",
    "\n",
    "        {tools_str}\n",
    "\n",
    "        ### INSTRUÇÕES DE FORMATO\n",
    "        Para usar uma ferramenta, você DEVE responder APENAS com um bloco JSON no seguinte formato, e nada mais:\n",
    "\n",
    "        {{\n",
    "            \"tool\": \"nome_da_ferramenta\",\n",
    "            \"parameters\": {{\n",
    "                \"parametro1\": \"valor\",\n",
    "                \"parametro2\": \"valor\"\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Se nenhuma ferramenta for necessária, responda diretamente ao usuário.\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            {'role' : 'system', 'content': system_instruction},\n",
    "            {'role' : 'user', 'content' : prompt}\n",
    "        ]\n",
    "\n",
    "        text = self.tokenizer.apply_chat_template( # Formata \n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    "        )\n",
    "        print(text)\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "        # conduct text completion\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=32768\n",
    "        )\n",
    "        output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "        # parsing thinking content\n",
    "        try:\n",
    "            # rindex finding 151668 (</think>)\n",
    "            index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "        except ValueError:\n",
    "            index = 0\n",
    "\n",
    "        thinking_content = self.tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "        content = self.tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "        print(\"thinking content:\", thinking_content)\n",
    "        print(\"content:\", content)\n",
    "        return content\n",
    "    \n",
    "    async def open_data_search(self, query: str, client, encoder) -> dict:\n",
    "\n",
    "        #encoder = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\", device='cpu')\n",
    "        translator = Translator()\n",
    "        #client = QdrantClient(path=\"../metadados/VectorStore/\") # Carrega vectorstore em disco\n",
    "\n",
    "        task = \"Você é um motor de busca, devolva dados mais relevantes com base na busca\"\n",
    "\n",
    "        query_pt = f\"Instrução: {task} Query: {query}\"\n",
    "        query_en = await translator.translate(query_pt, src='pt', dest='en')\n",
    "\n",
    "        query = query_en.text\n",
    "\n",
    "        print(\"Query em português:\", query_pt)\n",
    "        print(\"Query utilizada:\", query)\n",
    "\n",
    "        hits = self.client.query_points(\n",
    "            collection_name=\"Catalogo_metadados\",\n",
    "            query=self.encoder.encode(query).tolist(),\n",
    "            limit=20,\n",
    "        ).points\n",
    "\n",
    "        print(hits)\n",
    "\n",
    "        for hit in hits:\n",
    "            print(\"score:\", hit.score)\n",
    "            print(\"Titulo: \",hit.payload.get('title'))\n",
    "            print(\"Nome: \", hit.payload.get('nome'))\n",
    "            print(\"Descrição: \", hit.payload.get('descricao'))\n",
    "            print('\\n')\n",
    "\n",
    "    def chat(self, query: str, client, encoder) -> str:\n",
    "        #tool = eval(self.agent(query)).get('tool')\n",
    "        #print(tool)\n",
    "        await self.open_data_search(query, client, encoder)\n",
    "        #self,eval(tool)(query, client, encoder)\n",
    "\n",
    "    def clean_history(self):\n",
    "        self.history.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22cba5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7028/527675232.py:123: RuntimeWarning: coroutine 'Chatbot.open_data_search' was never awaited\n",
      "  self.open_data_search(query, client, encoder)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "chatbot = Chatbot(model=model, tokenizer=tokenizer)\n",
    "\n",
    "query = \"Quero dados sobre infecção hospitalar\"\n",
    "\n",
    "tool = chatbot.chat(query, client, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2406e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'open_data_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m fun = \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'open_data_search' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Tool\n",
    "def soma(a:int, b:int) -> Union[int, float]:\n",
    "    \"\"\"\n",
    "    Docstring for soma\n",
    "\n",
    "    Soma dois numeros de tipo int e/ou float\n",
    "    args:\n",
    "        a: int/float\n",
    "        b: int/float\n",
    "    Returns:\n",
    "        Retorna a soma a+b : int/float\n",
    "    \"\"\"\n",
    "    return a + b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
