{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c53b37b",
   "metadata": {},
   "source": [
    "# Create VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "key=\"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJqdGkiOiJINWNwUGpicUpFdFdKMjdTSlI5UFNNZUY1N09xQ1lRVWhjejJCa3UyTFNQa01qVVB5VUVTVWhNZFNOZnVhQnZRRmMtZFhYc0ZvUWFDSjVEVCIsImlhdCI6MTcxMDg0Njc4MX0.yzj8qQ2eq28LoKSp2KAOb05MmDSooirEwVB9LCtoDjg\"\n",
    "def gov_request(id_set, params=None):\n",
    "    url = \"https://dados.gov.br/dados/api/publico/conjuntos-dados/\" + id_set\n",
    "    response = requests.get(url, params=params, headers = {\"chave-api-dados-abertos\" : key})\n",
    "    \n",
    "    if response.headers.get('content-type') != 'application/json':\n",
    "        return print(response.headers.get('content-type'))\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8632e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json(file_path):\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a69a52",
   "metadata": {},
   "source": [
    "### Carrega catalogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c949c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq = read_json(\"../saves/catalogo_9990conjuntodeDados.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761c25f",
   "metadata": {},
   "source": [
    "### Carrega metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73da0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq1 = read_json(\"../saves/metados_9990.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530e542",
   "metadata": {},
   "source": [
    "## Estruturação dos metadados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e749e80",
   "metadata": {},
   "source": [
    "### Documents Catalogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bffb516",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "[documents.append(\n",
    "\n",
    "    {\n",
    "    \"id\": doc['id'],\n",
    "    \"title\": doc['title'],\n",
    "    \"nome\": doc['nome'],\n",
    "    'descricao': rq1[doc['id']][\"descricao\"],\n",
    "    \"catalogacao\": doc['catalogacao'],\n",
    "    \"nomeOrganizacao\": doc['nomeOrganizacao'],\n",
    "    \"ultimaAlteracaoMetadados\": doc['ultimaAlteracaoMetadados'],\n",
    "    \"ultimaAtualizacaoDados\": doc['ultimaAtualizacaoDados'],\n",
    "    \"isAtualizado\": doc['isAtualizado'],\n",
    "    }\n",
    "\n",
    ") for doc in rq]\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabfa897",
   "metadata": {},
   "source": [
    "### Salva objetos Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d54fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    with open('documents', 'ab') as arquivo_binario:\n",
    "        pickle.dump(doc, arquivo_binario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa524d0",
   "metadata": {},
   "source": [
    "### Carrega Objeto Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbe49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f7c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../saves/documents\", \"rb\") as arquivo_binario:\n",
    "  while True:\n",
    "    try:\n",
    "        documents.append(pickle.load(arquivo_binario))\n",
    "    except EOFError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8fc2dd",
   "metadata": {},
   "source": [
    "### Schema catalogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba9f2b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'string',\n",
       "  'title': 'string',\n",
       "  'nome': 'string',\n",
       "  'catalogacao': 'string',\n",
       "  'nomeOrganizacao': 'string',\n",
       "  'ultimaAlteracaoMetadados': 'string',\n",
       "  'ultimaAtualizacaoDados': 'string',\n",
       "  'isAtualizado': True}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "  {\n",
    "    \"id\": \"string\",\n",
    "    \"title\": \"string\",\n",
    "    \"nome\": \"string\",\n",
    "    \"catalogacao\": \"string\",\n",
    "    \"nomeOrganizacao\": \"string\",\n",
    "    \"ultimaAlteracaoMetadados\": \"string\",\n",
    "    \"ultimaAtualizacaoDados\": \"string\",\n",
    "    \"isAtualizado\": True\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9e045",
   "metadata": {},
   "source": [
    "### schema Detalhamento de conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"id\": \"string\",\n",
    "  \"titulo\": \"string\",\n",
    "  \"nome\": \"string\",\n",
    "  \"organizacao\": \"string\",\n",
    "  \"descricao\": \"string\",\n",
    "  \"licenca\": \"string\",\n",
    "  \"responsavel\": \"string\",\n",
    "  \"emailResponsavel\": \"string\",\n",
    "  \"periodicidade\": \"INVALIDO\",\n",
    "  \"temas\": [\n",
    "    {\n",
    "      \"name\": \"string\",\n",
    "      \"title\": \"string\"\n",
    "    }\n",
    "  ],\n",
    "  \"tags\": [\n",
    "    {\n",
    "      \"id\": \"string\",\n",
    "      \"name\": \"string\",\n",
    "      \"display_name\": \"string\"\n",
    "    }\n",
    "  ],\n",
    "  \"coberturaTemporalInicio\": \"2025-10-06\",\n",
    "  \"coberturaTemporalFim\": \"2025-10-06\",\n",
    "  \"coberturaEspacial\": \"INVALIDO\",\n",
    "  \"valorCoberturaEspacial\": \"string\",\n",
    "  \"granularidadeEspacial\": \"INVALIDO\",\n",
    "  \"versao\": \"string\",\n",
    "  \"atualizacaoVersao\": true,\n",
    "  \"visibilidade\": \"INVALIDO\",\n",
    "  \"descontinuado\": true,\n",
    "  \"dataDescontinuacao\": \"2025-10-06\",\n",
    "  \"reuso\": true,\n",
    "  \"recursos\": [\n",
    "    {\n",
    "      \"dataUltimaAtualizacaoArquivo\": \"string\",\n",
    "      \"dataCatalogacao\": \"string\",\n",
    "      \"quantidadeDownloads\": 0,\n",
    "      \"nomeArquivo\": \"string\",\n",
    "      \"link\": \"string\",\n",
    "      \"idConjuntoDados\": \"string\",\n",
    "      \"titulo\": \"string\",\n",
    "      \"formato\": \"string\",\n",
    "      \"tipo\": \"INVALIDO\",\n",
    "      \"numOrdem\": 0,\n",
    "      \"descricao\": \"string\",\n",
    "      \"tamanho\": 0,\n",
    "      \"id\": \"string\"\n",
    "    }\n",
    "  ],\n",
    "  \"dataUltimaAtualizacaoMetadados\": \"string\",\n",
    "  \"dataUltimaAtualizacaoArquivo\": \"string\",\n",
    "  \"dataCatalogacao\": \"string\",\n",
    "  \"atualizado\": \"string\",\n",
    "  \"dadosRacaEtnia\": true,\n",
    "  \"dadosGenero\": true,\n",
    "  \"ods\": [\n",
    "    0\n",
    "  ],\n",
    "  \"observanciaLegal\": \"string\",\n",
    "  \"dadosAbertos\": \"string\",\n",
    "  \"selo\": \"string\",\n",
    "  \"origemCadastro\": \"string\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f068234",
   "metadata": {},
   "source": [
    "## Criação da VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14cebc",
   "metadata": {},
   "source": [
    "### VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03fd1a",
   "metadata": {},
   "source": [
    "Será utilizado Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c057e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f1ac8f",
   "metadata": {},
   "source": [
    "Modelo de embedding para criação da VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48926426",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\", device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9436af",
   "metadata": {},
   "source": [
    "#### Cria vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2dace",
   "metadata": {},
   "source": [
    "Limpa memoria da GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189bf561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1f51e",
   "metadata": {},
   "source": [
    "Cria uma vectorStore em batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37295866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando batch 1 de 50\n",
      "Processando batch 2 de 50\n",
      "Processando batch 3 de 50\n",
      "Processando batch 4 de 50\n",
      "Processando batch 5 de 50\n",
      "Processando batch 6 de 50\n",
      "Processando batch 7 de 50\n",
      "Processando batch 8 de 50\n",
      "Processando batch 9 de 50\n",
      "Processando batch 10 de 50\n",
      "Processando batch 11 de 50\n",
      "Processando batch 12 de 50\n",
      "Processando batch 13 de 50\n",
      "Processando batch 14 de 50\n",
      "Processando batch 15 de 50\n",
      "Processando batch 16 de 50\n",
      "Processando batch 17 de 50\n",
      "Processando batch 18 de 50\n",
      "Processando batch 19 de 50\n",
      "Processando batch 20 de 50\n",
      "Processando batch 21 de 50\n",
      "Processando batch 22 de 50\n",
      "Processando batch 23 de 50\n",
      "Processando batch 24 de 50\n",
      "Processando batch 25 de 50\n",
      "Processando batch 26 de 50\n",
      "Processando batch 27 de 50\n",
      "Processando batch 28 de 50\n",
      "Processando batch 29 de 50\n",
      "Processando batch 30 de 50\n",
      "Processando batch 31 de 50\n",
      "Processando batch 32 de 50\n",
      "Processando batch 33 de 50\n",
      "Processando batch 34 de 50\n",
      "Processando batch 35 de 50\n",
      "Processando batch 36 de 50\n",
      "Processando batch 37 de 50\n",
      "Processando batch 38 de 50\n",
      "Processando batch 39 de 50\n",
      "Processando batch 40 de 50\n",
      "Processando batch 41 de 50\n",
      "Processando batch 42 de 50\n",
      "Processando batch 43 de 50\n",
      "Processando batch 44 de 50\n",
      "Processando batch 45 de 50\n",
      "Processando batch 46 de 50\n",
      "Processando batch 47 de 50\n",
      "Processando batch 48 de 50\n",
      "Processando batch 49 de 50\n",
      "Processando batch 50 de 50\n",
      "Processando batch 51 de 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "coletion: Armazena conjunto de points\n",
    "PointsStructure:  Armazena ids, vetores(embeddings) e payload\n",
    "payload: metada sobre os vetores\n",
    "\n",
    "vetor: recebe embedding do modelo, no caso abaixo será utilizado description como conteudo a ser buscado\n",
    "\n",
    "\n",
    "No for abaixo, o ideal é fazer em batches, para evitar estouro de memoria RAM/GPU\n",
    "'''\n",
    "\n",
    "batches = []\n",
    "num_batches = 50\n",
    "\n",
    "for idx, doc in enumerate(documents):\n",
    "    if idx % (len(documents)//num_batches) == 0:\n",
    "        print(f'Processando batch {idx // (len(documents)//num_batches) + 1} de {num_batches}')\n",
    "        torch.cuda.empty_cache() # Limpa memoria GPU\n",
    "\n",
    "    rq1_doc = rq1.get(doc['id'])\n",
    "    if rq1_doc is not None and rq1_doc.get(\"descricao\") is not None:\n",
    "        point = models.PointStruct(\n",
    "            id=idx,\n",
    "            vector=encoder.encode(rq1_doc[\"descricao\"]).tolist(),\n",
    "            payload=doc\n",
    "        )\n",
    "\n",
    "        batches.append(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7386205",
   "metadata": {},
   "source": [
    "Cria objeto client na memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceadb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Vale testar duas abordagens sugeridas na documentação do Qdrant:\n",
    "1. Criar a coleção com quantização escalar (Scalar Quantization) para reduzir o tamanho do armazenamento.\n",
    "2. Criar a coleção on-disk, para diminuir o uso da memoria RAM.\n",
    "\n",
    "quantization_config=models.ScalarQuantization(\n",
    "    scalar=models.ScalarQuantizationConfig(\n",
    "        type=models.ScalarType.INT8,\n",
    "        quantile=0.99,\n",
    "        always_ram=True,\n",
    "    )\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "clientd.create_collection(\n",
    "    collection_name=\"catalogo\", # nome da coleção\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=encoder.get_sentence_embedding_dimension(),  # Vector size is defined by used model\n",
    "        distance=models.Distance.COSINE, # Metrica de similaridade\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de62e94",
   "metadata": {},
   "source": [
    "Salva vetores no objeto Clientd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "coletion_name: Nome da coleção a ser utilizada\n",
    "points: lista de pointStructures a serem inseridos\n",
    "batch_size: Tamanho do batch para inserção\n",
    "'''\n",
    "clientd.upload_points(\n",
    "    collection_name=\"catalogo\",\n",
    "    points=batches,\n",
    "    batch_size=1000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
