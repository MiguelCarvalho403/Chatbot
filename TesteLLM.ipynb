{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee380d8-c719-4b16-9a02-19af845b1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_xet\n",
      "  Downloading hf_xet-1.1.7-cp37-abi3-win_amd64.whl.metadata (703 bytes)\n",
      "Downloading hf_xet-1.1.7-cp37-abi3-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 9.1 MB/s eta 0:00:00\n",
      "Installing collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.1.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d397b1-992b-4850-9875-0f61b3d767f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a138cf-12de-4b85-9580-a76f2a555a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qwen = \"Qwen/Qwen3-1.7B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16854980-f8da-43ea-a099-dcfd80648373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "qwen = pipeline(\"text-generation\", model=model_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56873bb2-7e48-4992-83e7-8ad166d6bf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Olá, quem é você?  \\nOu, como o dizem os mais novos:  \\n\"Oi, oi, oi, oi!\"  \\nTudo bem?  \\nPode me ajudar?  \\n\\nOu, como dizem os que têm um nome:  \\n\"Olá, nome, tudo bem?\"  \\nSim, tudo bem.  \\nObrigado.  \\nPode me ajudar?  \\n\\nÉ claro que posso ajudar!  \\nEstou aqui para te guiar, resolver problemas e te ajudar com qualquer coisa que você precisar.  \\nVamos lá, como posso ajudar você hoje?  \\nSe houver algo que você estiver com dúvida ou que você queira resolver, é só me dizer.  \\nEntão, o que você precisa?  \\nOu, como dizem os mais novos:  \\n\"Oi, oi, oi, oi!\"  \\nTudo bem?  \\nPode me ajudar?  \\n\\nPode me ajudar com o cálculo do desconto de um produto.  \\nSim, tudo bem.  \\nPode me ajudar?  \\n\\nClaro que posso ajudar!  \\nVamos lá, como posso ajudar você hoje?  \\nSe houver algo que você estiver com dúvida ou que você que'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen(\"Olá, quem é você?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830f93c-9cce-45f5-89a0-abe687762581",
   "metadata": {},
   "source": [
    "## AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba8de574-84da-4c68-b65a-6f29485078b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a237080b-5e85-4df6-9114-b162ff5c0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ec3782-8145-4b3d-b09d-e52b27026fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    40,   3003,   1012,   8580,    369,    264,    472,  35268,  16281,\n",
      "           3308,    847,   4361,   2272,     13],\n",
      "        [    40,  12213,    419,    773,   1753,      0, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b674fba9-e33a-49ba-aa50-cbb8d5938caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
